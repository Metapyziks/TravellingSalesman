\documentclass[a4paper,11pt]{article}

\usepackage{mathtools}
\usepackage{lipsum}
\usepackage{fullpage}
\usepackage{tabu}
\usepackage{wrapfig}
\usepackage{array,ragged2e,pst-node,pst-dbicons}
\usepackage{graphicx}

\title{Computer System II Networks Assignment}
\date{\today}
\author{James King}

\begin{document}
\maketitle

\begin{abstract}
\emph{The Travelling Salesman Problem is an example of the NP-Complete class of
problems; attempting to find the optimal solution by trying every possibility
would require an obscene amount of time for all but the smallest of input
sizes. This report describes two methods for finding decent solutions in a 
reasonable amount of time. The first is a type of stochastic gradient descent,
and the second is a nature inspired algorithm that models a simple ant colony.
A piece of analysis software was also produced to try and display each given
input in a form that is understandable to humans.}
\end{abstract}

\section{General Data Structures}
Each city graph, after being loaded from an input file, is stored in a 2D
integer array in such a way that the value in column $i$ and row $j$ is the
distance between city $i$ and city $j$. Representing the graph in this form
meant that checking the distance between two cities is a simple and fast
operation, and I hoped this would lead to my search algorithms being more time
efficient.

Routes are represented as fixed length one dimensional integer arrays, with
each value in the array being the index of the associated city. Each route also
has two numbers stored inside it that record the number of cities in the route
and the total cost of the route (the sum of the distances between each city in
the route). The value for the route cost is initially set to $-1$, and when it
is requested and its value is $-1$ it recalculates this cost. Additionally, any
operations that could change the length of the route set this value back to
$-1$, signalling that the value needs to be recalculated when next requested.

When an empty route is first created, the values in its city array are the
indexes of each city in ascending order. When the $i$th city is added to the
route, the relevant index is swapped with the value that was at the $i$th
position. This means that for a route of length $j$, all values in the array
from $j+1$ onwards are the indexes of cities that are not currently in the tour
and therefore can be selected to be added to the tour. I have also provided the
facility of selecting the $k$th best city from this subset, using the end of
the array as a buffer which is partially ordered until the city that is $k$th
best using a given comparison criteria is found.

\section{Algorithms}
\subsection{Algorithm A}
My first algorithm is a combined stochastic gradient descent and constructive
search. The algorithm starts with an empty route. For each step, a random city
from the set of unvisited cities is added to the end of the route. Next, a
hill climbing algorithm operates on the tour until no new improvements are
found. This process repeats, adding a new city every step, until the tour is
complete. Then this tour's length is calculated and compared with the shortest
found so far. If this is a new shortest tour, it is recorded and the whole
algorithm starts again.

The hill climbing method used in this algorithm is based around reversing
sections of the tour. To perform the reversal between two cities $T_i$ and
$T_j$ (where $T_i$ is the $i$th city in tour $T$), first the positions of $T_i$
and $T_j$ are swapped in the tour. Then $i$ is incremented by $1$, and $j$ is
decreased by $1$. The swapping and incrementing / decrementing process repeats
until $i \ge j$, which is when all cities between the initial two selected ones
have been reversed in place.

The two cities to reverse between are chosen by checking every pair of cities
for the pair that would give the largest improvement to tour length if
reversed. The operation to find the change in tour length is made simple by the
fact that only two connections will be changed in a way that could affect the
tour length - the connections between the cities inside the swapped section are
only reversed but their length stays the same. The change in tour length is
therefore found like this:

$$(|\overrightarrow{{T_{i-1}}{T_i}}|
+ |\overrightarrow{{T_j}{T_{j+1}}}|)
- (|\overrightarrow{{T_{i-1}}{T_j}}|
+ |\overrightarrow{{T_i}{T_{j+1}}}|)$$

\noindent
Here $|\overrightarrow{{T_i}{T_j}}|$ is the distance between city $T_i$ and
$T_j$ as described by the city graph given as input.

Because of the nature of the reversal, some sets of pairs of cities would 
produce the same change in tour length when reversed. Pairs that would have
the same effect on tour length as others can be safely excluded to improve 
performance. I achieve this by picking the index $i$ of the first city, and the 
number of cities to reverse $c$, where $c \ge 2$ and
$c \le \frac{toursize}{2}$. This excludes swapping a city with itself (which
will never change the tour length) and any reversals that would return the same 
result as a previous one but with the whole tour in reverse.

The tour construction and reversal process is very fast, and because the
process is independent of any other systems related to the generation process
it may be easily threaded. This algorithm relies on being executed many, many
times to increase the probability of finding the optimal tour, and through
multithreading and other more general optimising techniques I improved the
speed of the algorithm to run thousands of tour tests a second. While the
algorithm may not be the smartest, by running it long enough it produced some
pretty small tour sizes.

Initially the algorithm would only run the reversal improvement method after
the entire random tour was generated. This produced better results less
frequently and was actually slower despite running the improvement algorithm
only once per tour. The speed increase when improving after every new city
added is probably because the tour would require less reversal operations to
find a local minima when the tour is larger (and the reversal algorithm is more
expensive) if the tour is constantly being maintained as it is built. However,
I am not certain that it is possible for the absolute optimal tour to be found
in every case when the tour is being improved as it is built whereas it is
trivial to see that finding the optimal tour is possible when only improving
after a random tour is built. In the end I decided to trade the possibility of
finding the optimal tour for finding sub optimal but decent tours more
frequently.

\begin{figure}
\begin{center}
\begin{tabular}{c}
\Large
\Circlenode[radius=4mm,linestyle=dashed]{f1start}{~}
\hskip 5mm
\Circlenode[radius=4mm]{f1A}{A} \ncline[linestyle=dashed]{f1start}{f1A}
\hskip 5mm
\Circlenode[radius=4mm]{f1B}{B} \ncline{f1A}{f1B}
\hskip 5mm
\Circlenode[radius=4mm]{f1C}{C} \ncline{f1B}{f1C}
\hskip 5mm
\Circlenode[radius=4mm]{f1D}{D} \ncline{f1C}{f1D}
\hskip 5mm
\Circlenode[radius=4mm]{f1E}{E} \ncline{f1D}{f1E}
\hskip 5mm
\Circlenode[radius=4mm]{f1F}{F} \ncline{f1E}{f1F}
\hskip 5mm
\Circlenode[radius=4mm]{f1G}{G} \ncline{f1F}{f1G}
\hskip 5mm
\Circlenode[radius=4mm,linestyle=dashed]{f1end}{~}
\ncline[linestyle=dashed]{f1G}{f1end}
\ncarc[arcangle=30,linestyle=dashed]{->}{f1B}{f1F}
\ncarc[arcangle=30,linestyle=dashed]{<-}{f1E}{f1A}
\\[1cm]
\Large
\Circlenode[radius=4mm,linestyle=dashed]{f2start}{~}
\hskip 5mm
\Circlenode[radius=4mm]{f2A}{A} \ncline[linestyle=dashed]{f2start}{f2A}
\hskip 5mm
\Circlenode[radius=4mm]{f2E}{E} \ncline{f2A}{f2E}
\hskip 5mm
\Circlenode[radius=4mm]{f2D}{D} \ncline{f2E}{f2D}
\hskip 5mm
\Circlenode[radius=4mm]{f2C}{C} \ncline{f2D}{f2C}
\hskip 5mm
\Circlenode[radius=4mm]{f2B}{B} \ncline{f2C}{f2B}
\hskip 5mm
\Circlenode[radius=4mm]{f2F}{F} \ncline{f2B}{f2F}
\hskip 5mm
\Circlenode[radius=4mm]{f2G}{G} \ncline{f2F}{f2G}
\hskip 5mm
\Circlenode[radius=4mm,linestyle=dashed]{f2end}{~}
\ncline[linestyle=dashed]{f2G}{f2end}
\end{tabular}
\end{center}
\caption{Segment of a tour before and after a reversal is applied between
	\emph{B} and \emph{E}, with the two new connections to be added represented
	by dashed arcs. The only connections that differ in cost to the original
	tour are the new connections from \emph{A} to \emph{E} and \emph{B} to
	\emph{F}.}
\end{figure}

\subsection{Algorithm B}

Before I started work on my second method I wanted to have a go at visualising
the graphs in a way that attempts to portray the distances between each node,
thinking that with some extra insight into how the graphs were laid out I would
be able to think of better methods of solving the problem. I wrote a simple
program that essentially simulates springs between each city with strengths
related to the distance between each city pair, and allow the cities to move
until they are at an equilibrium. This method would work best for graphs where
each cost to travel between two cities was based on the euclidean distance
between two points that represent those cities.

\begin{wrapfigure}{r}{0.5\textwidth}
\includegraphics[width=0.48\textwidth]{175vis}
\caption{Visualisation of the 175 city graph with the current shortest route.}
\end{wrapfigure}

This worked much more successfully than I expected. I was anticipating all the
graphs having distances that were entirely random, and therefore not euclidean.
While this appears to be true for some graphs, the 12, 58, 175 and 535 city
graphs may be visualised quite nicely by the program. Looking at how different
solutions given by my first method navigated around the visualised graph showed
that some groups of cities would be navigated in similar ways each time, but
the order in which these groups were visited would differ. A decent algorithm
would be able to preserve subsections of the tour that were close to optimal
but freely shift them around and reorder them to attempt to optimise the entire
route.

I was aware of the Ant Colony heuristic from a previous project, but back then
I had implemented it based on a rough idea of how I thought the algorithm
worked. From what I remembered, the method should have the ability to do as I
described, optimising subsections of the tour but leaving the overall route
flexible.

The Ant Colony heuristic essentially tries to mimic the path finding and route
optimisation method that ants have evolved in nature. An ant that first finds a
route to some food leaves a pheromone trail as it travels between the food and
the colony. This pheromone attracts other ants to follow it, which also
reinforce the trail with their own scent. Every so often, an ant will randomly
take a slight variation of the route which more ants may follow. Whichever
route variation is shortest will have a higher amount of traffic; at first
because the route is shorter so it can be travelled more times in an hour than
a longer one, and later because it has more pheromones along it. This is
emulated in a searcher by having independent ant agents that traverse a graph,
choosing the next city to move to based on the amount of virtual pheromone left
on the paths to each city and the path distance. Each time an ant completes a
tour it leaves virtual pheromones along the tour route, with a potency 
inversely proportional to the tour length.

I implemented this method as a searcher, but the initial results were fairly
poor. I modified my visualiser to see which paths the ants were taking, and saw
that they very rarely took routes that had high path cost. I found an issue
with my path selection algorithm that was causing this behaviour, and after
fixing it the results given were much improved.

\section{Results Analysis}
The results displayed in Table 1 are the all-time lowest tour lengths
achieved by each algorithm. The table also shows the difference between the
results of the two algorithms, and the difference as a percentage of the
shortest tour's length.

\begin{table}[l]
\input{resultstable}
\caption{Final results of both algorithms for each given city, and the
	difference between them.}
\end{table}

\lipsum[1-5]
\end{document}
